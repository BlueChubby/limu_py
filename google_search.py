import json
import re
from ddgs import DDGS


def smart_search(keyword, target_count=5):
    """
    æ™ºèƒ½æœç´¢å‡½æ•° V2ï¼š
    1. æ”¯æŒæ­£åˆ™æ¨¡ç³ŠåŒ¹é… (è§£å†³ Gemini3 vs Gemini 3.0)
    2. æ”¯æŒä¸Šä¸‹æ–‡è¯­ä¹‰éªŒè¯ (å‰”é™¤ USB çº¿æã€é£Ÿå“æ ‡å‡†ç­‰æ— å…³å†…å®¹)
    3. ä¼˜å…ˆæœç´¢ Newsï¼Œé™çº§ä½¿ç”¨ Text
    """

    print(f"ğŸ” å¼€å§‹æœç´¢: '{keyword}' (ç›®æ ‡: {target_count} æ¡)")

    # --- æ ¸å¿ƒå‡çº§ï¼šæ›´æ™ºèƒ½çš„éªŒè¯é€»è¾‘ ---
    def is_valid_result(item, original_query):
        # 1. å‡†å¤‡æ•°æ®
        title = item.get('title', '').lower()
        body = (item.get('body') or item.get('snippet') or '').lower()
        content = title + " " + body
        query_lower = original_query.lower()

        # --- A. é’ˆå¯¹ Gemini3 çš„ç‰¹æ®Šæ­£åˆ™å¤„ç† ---
        if "gemini" in query_lower and "3" in query_lower:
            # æ­£åˆ™è§£é‡Šï¼šåŒ¹é… geminiï¼Œåé¢æ¥ä»»æ„ä¸ª(ç©ºæ ¼/æ¨ªæ /ç‚¹)ï¼Œç„¶åæ¥3
            # èƒ½åŒ¹é…: gemini3, gemini 3, gemini-3, gemini 3.0
            if not re.search(r'gemini[\s\-\.]*3', content):
                return False

            # ã€ä¸Šä¸‹æ–‡é”šç‚¹ã€‘å¿…é¡»åŒ…å«ä»¥ä¸‹è¯æ±‡ä¹‹ä¸€ï¼Œé˜²æ­¢åŒ¹é…åˆ° "iFi Audio Gemini3.0" çº¿æ
            context_anchors = ['google', 'ai', 'llm', 'model', 'intelligence', 'reasoning']
            if not any(anchor in content for anchor in context_anchors):
                return False

            # å¦‚æœåŸè¯é‡Œæœ‰ proï¼Œé‚£ä¹ˆç»“æœé‡Œä¹Ÿå¿…é¡»æœ‰ pro
            if "pro" in query_lower and "pro" not in content:
                return False

            return True

        # --- B. é’ˆå¯¹ Codex çš„ç‰¹æ®Šå¤„ç† ---
        if "codex" in query_lower:
            # å¿…é¡»åŒ…å« codex
            if "codex" not in content:
                return False
            # å¦‚æœæœ OpenAIï¼Œå¿…é¡»åŒ…å« OpenAI
            if "openai" in query_lower and "openai" not in content:
                return False

            # ã€è´Ÿé¢è¯è¿‡æ»¤ã€‘æ’é™¤é£Ÿå“ã€æ‹¼å›¾ç­‰å¹²æ‰°
            forbidden = ['cashew', 'food', 'puzzle', 'game', 'nintendo', 'silenda']
            if any(bad in content for bad in forbidden):
                return False

            return True

        # --- C. é»˜è®¤é€»è¾‘ï¼šè¯æ ¹å…¨åŒ…å« ---
        # å¯¹äº "nano banana" è¿™ç§ï¼Œç»§ç»­ä½¿ç”¨åˆ‡åˆ†åŒ¹é…
        required_terms = query_lower.split()
        return all(term in content for term in required_terms)

    # --- æ ‡å‡†åŒ–å‡½æ•° ---
    def normalize_item(item, source_type):
        url = item.get('url') or item.get('href')
        return {
            "title": item.get('title'),
            "body": item.get('body') or item.get('snippet'),
            "url": url,
            "date": item.get('date') or "Unknown",
            "source": item.get('source') or "Web Search",
            "type": source_type
        }

    final_results = []
    seen_urls = set()

    # --- ä¼˜åŒ–æŸ¥è¯¢è¯ ---
    # æœç´¢å¼•æ“é€šå¸¸å¯¹åˆ†å¼€çš„è¯ç†è§£æ›´å¥½ï¼Œæ¯”å¦‚æœ "Gemini 3" æ¯” "Gemini3" ç»“æœå¤š
    search_query = keyword.replace("Gemini3", "Gemini 3")

    # ==========================================
    # é˜¶æ®µ 1: News æœç´¢
    # ==========================================
    print("1ï¸âƒ£  æ­£åœ¨è¿›è¡Œ News æœç´¢...")
    try:
        news_gen = DDGS().news(
            query=f'"{search_query}"',  # ä½¿ç”¨ä¼˜åŒ–åçš„å…³é”®è¯
            region="us-en",
            safesearch="off",
            timelimit="m",
            max_results=target_count * 3
        )

        for res in news_gen:
            if len(final_results) >= target_count: break

            url = res.get('url')
            # ä¼ å…¥åŸå§‹ keyword ç”¨äºåˆ¤æ–­é€»è¾‘
            if url not in seen_urls and is_valid_result(res, keyword):
                final_results.append(normalize_item(res, "News"))
                seen_urls.add(url)

    except Exception as e:
        print(f"   âš ï¸ News æœç´¢å‡ºç°é—®é¢˜: {e}")

    print(f"   -> News é˜¶æ®µè·å–åˆ° {len(final_results)} æ¡æœ‰æ•ˆç»“æœã€‚")

    # ==========================================
    # é˜¶æ®µ 2: Text æœç´¢
    # ==========================================
    needed = target_count - len(final_results)

    if needed > 0:
        print(f"2ï¸âƒ£  æ•°é‡ä¸è¶³ï¼Œè¡¥é½ {needed} æ¡ (Text æœç´¢)...")
        try:
            text_gen = DDGS().text(
                query=f'"{search_query}"',  # ä½¿ç”¨ä¼˜åŒ–åçš„å…³é”®è¯
                region="us-en",
                safesearch="off",
                timelimit="y",
                max_results=needed * 5,
                # backends="google" # æ³¨ï¼šæ–°ç‰ˆåº“é€šå¸¸ä¸éœ€è¦æŒ‡å®š backendï¼Œå»æ‰ä»¥é˜²æŠ¥é”™
            )

            for res in text_gen:
                if len(final_results) >= target_count: break

                url = res.get('href')
                if url not in seen_urls and is_valid_result(res, keyword):
                    final_results.append(normalize_item(res, "Web Text"))
                    seen_urls.add(url)

        except Exception as e:
            print(f"   âš ï¸ Text æœç´¢å‡ºç°é—®é¢˜: {e}")
    else:
        print("âœ… News ç»“æœå·²æ»¡è¶³æ•°é‡ï¼Œè·³è¿‡ Text æœç´¢ã€‚")

    return final_results


# ==========================================
# è¿è¡Œæµ‹è¯•
# ==========================================
if __name__ == "__main__":
    # æµ‹è¯•åˆ—è¡¨ï¼šåŒ…å«å®¹æ˜“æ­§ä¹‰çš„è¯å’Œå†™æ³•ä¸è§„èŒƒçš„è¯
    list_keywords = ["OpenAI Codex", "Gemini3 Pro", "Antigravity", "nano banana"]

    for query_keyword in list_keywords:
        count_needed = 10  # è®¾ä¸º 5 æ¡æ–¹ä¾¿æµ‹è¯•
        results = smart_search(query_keyword, count_needed)

        print("\n" + "=" * 40)
        print(f"æœ€ç»ˆç»“æœ: {query_keyword} (å…± {len(results)} æ¡)")
        print("=" * 40)
        # åªæ‰“å°å‰2æ¡çš„é¢„è§ˆï¼Œé˜²æ­¢æ§åˆ¶å°åˆ·å±å¤ªé•¿
        if results:
            print(json.dumps(results, indent=4, ensure_ascii=False))
            # print(f"Title [0]: {results[0]['title']}")
            # print(f"Type  [0]: {results[0]['type']}")
            # print(f"URL   [0]: {results[0]['url']}")
        else:
            print("âŒ æœªæ‰¾åˆ°ç»“æœ")